# ğŸ§® LabVIEW Open Benchmark Suite (LOBS)

**An open, reproducible, and community-driven benchmarking initiative for LabVIEW GPU and CPU acceleration.**

---

## ğŸ¯ Purpose

The **LabVIEW Open Benchmark Suite (LOBS)** aims to establish a transparent and vendor-neutral standard for benchmarking computational performance in the **LabVIEW ecosystem**.

Inspired by **SPEC**, **MLPerf**, and the **Graiphic Benchmarking Series**, LOBS provides a shared framework where developers, researchers, and toolkit vendors can:
- run **reproducible test benches** on their own hardware,
- **compare results** under common conditions,
- and **contribute new workloads** to enrich the suite.

---

## âš™ï¸ Goals

- ğŸ§© **Unify performance evaluation** across GPU, CPU, FPGA, and hybrid backends.  
- ğŸ” **Ensure reproducibility** via open-source VIs, datasets, and hardware specs.  
- ğŸ¤ **Foster collaboration** between toolkit vendors, users, and NI partners.  
- ğŸ“ˆ **Promote transparency** â€” performance is beautiful when itâ€™s explainable.  

---

## ğŸ§  Scope

LOBS will progressively cover the following categories:

| Category | Example Workloads | Typical Toolkits |
|-----------|-------------------|------------------|
| **Linear Algebra** | GEMM, Conv2D | Accelerator, CuLab, GÂ²CPU |
| **Signal Processing** | FFT, Filtering, Cross-Correlation | Accelerator, NI Sound/Vision Modules |
| **Arithmetic & Logic** | Element-wise Add/Neg/Mul/Div | All GPU Toolkits |
| **AI & Inference** | ONNX Runtime models, CNNs, Transformers | Accelerator, OpenVINO, ONNX DNN |
| **Memory & IO** | Transfer latency, DMA throughput | GÂ²CPU, custom SDKs |
| **Energy Profiling (future)** | Joule-per-operation metrics | GO HW integration |

---

## ğŸ”¬ Methodology Principles

Every benchmark included in LOBS must:
1. Be **open source**, reproducible by anyone with LabVIEW Professional or Community Edition.  
2. Include clear **hardware + driver configuration** documentation.  
3. Report **execution time (sec)** and **numerical correctness**.  
4. Be **independent** of vendor marketing â€” results speak through data.  

All submissions will be peer-reviewed through GitHub issues and merged once verified.

---

## ğŸ“˜ Reference Benchmark

The **Graiphic Whitepaper â€œBenchmarking the Futureâ€** serves as the **LOBS Reference 0** â€” the baseline set of tests for GEMM, Arithmetic, Complex, and Signal Processing workloads.  

ğŸ“„ [Read the Whitepaper â†’](../Benchmarking%20the%20Future%20Comparing%20LabVIEW%20GPU%20Toolkits%20CuLab%2C%20G2CPU%2C%20and%20the%20Graiphic%20Accelerator.1.0.pdf)

---

## ğŸ§© How to Contribute

We welcome contributions from engineers, researchers, and toolkit developers.

### ğŸ›  Submit a New Test Case
1. Fork this repository.  
2. Add your test under `/LabVIEW Open Benchmark Suite/Benchmarks/<Category>/`.  
3. Include:
   - VI(s) and test data  
   - Hardware configuration (CPU, GPU, driver, OS)  
   - Expected results and performance metrics  
4. Submit a **Pull Request** with a short description.

### ğŸ§¾ Share Replication Results
Use GitHub **Issues** to post:
- screenshots,  
- execution logs,  
- or raw numeric results from your hardware.

All reproducible submissions will be cited in future versions of the benchmark report.

---

## ğŸ§­ Roadmap

| Phase | Objective | Status |
|--------|------------|--------|
| **0** | Publish reference benchmark (Graiphic Whitepaper) | âœ… Done |
| **1** | Community replication & verification | ğŸŸ¢ Ongoing |
| **2** | Add AI inference and deep learning test suite | â³ Planned |
| **3** | Energy & efficiency measurement (GO HW integration) | ğŸš§ In progress |
| **4** | Publish v1.0 Open Benchmark Specification | ğŸ“… 2026 |

---

## ğŸ¤ Contributors & Partners

| Name | Organization | Role |
|------|---------------|------|
| **Graiphic** | France | Founder & Core Maintainer |
| **Open contributors** | â€“ | Replication, validation, extensions |

If your organization wants to join as a co-maintainer or reviewer, please contact:  
ğŸ“§ [benchmark@graiphic.io](mailto:contact@graiphic.io)

---

## ğŸ§­ Motto

> â€œBenchmarking isnâ€™t about whoâ€™s fastest â€”  
> itâ€™s about understanding why.â€  

---

## ğŸ“„ License

All contents of LOBS are released under the **MIT License** for maximum openness.

---

**Â© 2025 Graiphic â€” LabVIEW Open Benchmark Suite (LOBS)**  
Part of the Graiphic Open Science initiative.

